#!/usr/bin/env python
"""
Downloads your last 3200 tweets
"""
USER = "_rami_"
FILE = "%s.twitter.sqlite.db" % USER

import os
import sqlite3
import urllib
import json
import email.utils
from datetime import tzinfo 
import time

if os.path.exists(FILE):
	conn = sqlite3.connect(FILE)
	c = conn.cursor()
	c.execute('SELECT MAX(id) FROM tweets')
	last = c.fetchone()[0]
	if last is None:
		last = 0
else:
	conn = sqlite3.connect(FILE)
	c = conn.cursor()
	c.execute('''CREATE TABLE tweets (id text unique on conflict ignore, text text, timestamp real)''')
	last = 0

maxid = ''
for page in range(1,17): # Absolute limit by twitter :(
	if page == 1:
		if last != 0:
			f = urllib.urlopen("https://api.twitter.com/1/statuses/user_timeline.json?include_entities=true&include_rts=false&trim_user=1&screen_name=%s&count=200&since_id=%s" % (USER, last))
		else:
			f = urllib.urlopen("https://api.twitter.com/1/statuses/user_timeline.json?include_entities=true&include_rts=false&trim_user=1&screen_name=%s&count=200" % (USER))
	else:
		if last != 0:
			f = urllib.urlopen("https://api.twitter.com/1/statuses/user_timeline.json?include_entities=true&include_rts=false&trim_user=1&screen_name=%s&count=200&since_id=%s&max_id=%s" % (USER, last, maxid))
		else:
			f = urllib.urlopen("https://api.twitter.com/1/statuses/user_timeline.json?include_entities=true&include_rts=false&trim_user=1&screen_name=%s&count=200&max_id=%s" % (USER, maxid))

	tree = json.loads(f.read())
	if len(tree) == 0:
		break
	else:
		for tweet in tree:
			timestamp = time.mktime(email.utils.parsedate(tweet['created_at']))
			c.execute("INSERT INTO tweets (id, text, timestamp) VALUES (?,?,?)",
				(tweet['id'], tweet['text'], timestamp))
		maxid = tweet['id']
	conn.commit()
	print("%d pages downloaded" % page)

c.close()
conn.close()
